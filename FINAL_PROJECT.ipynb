{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"FINAL_PROJECT.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"JW55pczginXZ","colab_type":"code","outputId":"61a3728a-dece-4c3f-f588-d16fbb66822f","executionInfo":{"status":"ok","timestamp":1547042020075,"user_tz":-60,"elapsed":29525,"user":{"displayName":"AFOLARIN LAWAL","photoUrl":"https://lh4.googleusercontent.com/-P4xQqKQpsvw/AAAAAAAAAAI/AAAAAAAAANA/k3L-3t5Tctg/s64/photo.jpg","userId":"02010015626091756673"}},"colab":{"base_uri":"https://localhost:8080/","height":146}},"cell_type":"code","source":["# Install a Drive FUSE wrapper.\n","# https://github.com/astrada/google-drive-ocamlfuse\n","!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n","!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n","!apt-get update -qq 2>&1 > /dev/null\n","!apt-get -y install -qq google-drive-ocamlfuse fuse"],"execution_count":3,"outputs":[{"output_type":"stream","text":["E: Package 'python-software-properties' has no installation candidate\n","Selecting previously unselected package google-drive-ocamlfuse.\n","(Reading database ... 110845 files and directories currently installed.)\n","Preparing to unpack .../google-drive-ocamlfuse_0.7.1-0ubuntu3~ubuntu18.04.1_amd64.deb ...\n","Unpacking google-drive-ocamlfuse (0.7.1-0ubuntu3~ubuntu18.04.1) ...\n","Setting up google-drive-ocamlfuse (0.7.1-0ubuntu3~ubuntu18.04.1) ...\n","Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n"],"name":"stdout"}]},{"metadata":{"id":"YTcJ7LQli0mM","colab_type":"code","colab":{}},"cell_type":"code","source":["# Generate auth tokens for Colab\n","from google.colab import auth\n","auth.authenticate_user()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"V4h6UzXejHwY","colab_type":"code","outputId":"782657ed-7447-4247-fc60-908ab3ab9164","executionInfo":{"status":"ok","timestamp":1547042085913,"user_tz":-60,"elapsed":24637,"user":{"displayName":"AFOLARIN LAWAL","photoUrl":"https://lh4.googleusercontent.com/-P4xQqKQpsvw/AAAAAAAAAAI/AAAAAAAAANA/k3L-3t5Tctg/s64/photo.jpg","userId":"02010015626091756673"}},"colab":{"base_uri":"https://localhost:8080/","height":110}},"cell_type":"code","source":["# Generate creds for the Drive FUSE library.\n","from oauth2client.client import GoogleCredentials\n","creds = GoogleCredentials.get_application_default()\n","import getpass\n","!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n","vcode = getpass.getpass()\n","!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n","··········\n","Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n","Please enter the verification code: Access token retrieved correctly.\n"],"name":"stdout"}]},{"metadata":{"id":"sNtbHZ1_j0hP","colab_type":"code","colab":{}},"cell_type":"code","source":["# Create a directory and mount Google Drive using that directory.\n","!mkdir -p drive\n","!google-drive-ocamlfuse drive"],"execution_count":0,"outputs":[]},{"metadata":{"id":"XQFx4KM9kHHm","colab_type":"code","outputId":"c99830ba-e4da-4bff-c773-6d2124b5160f","executionInfo":{"status":"ok","timestamp":1547042160157,"user_tz":-60,"elapsed":58822,"user":{"displayName":"AFOLARIN LAWAL","photoUrl":"https://lh4.googleusercontent.com/-P4xQqKQpsvw/AAAAAAAAAAI/AAAAAAAAANA/k3L-3t5Tctg/s64/photo.jpg","userId":"02010015626091756673"}},"colab":{"base_uri":"https://localhost:8080/","height":368}},"cell_type":"code","source":["# http://pytorch.org/\n","from os import path\n","from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n","platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n","\n","accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n","\n","!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.0-{platform}-linux_x86_64.whl torchvision\n","!pip install pillow==4.1.1\n","%reload_ext autoreload\n","%autoreload\n","!pip install PIL\n","!pip install image"],"execution_count":7,"outputs":[{"output_type":"stream","text":["tcmalloc: large alloc 1073750016 bytes == 0x5b93a000 @  0x7fc35a48d2a4 0x591a07 0x5b5d56 0x502e9a 0x506859 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x504c28 0x502540 0x502f3d 0x507641\n","Collecting pillow==4.1.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/36/e5/88b3d60924a3f8476fa74ec086f5fbaba56dd6cee0d82845f883b6b6dd18/Pillow-4.1.1-cp36-cp36m-manylinux1_x86_64.whl (5.7MB)\n","\u001b[K    100% |████████████████████████████████| 5.7MB 7.1MB/s \n","\u001b[?25hRequirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow==4.1.1) (0.46)\n","Installing collected packages: pillow\n","  Found existing installation: Pillow 5.4.1\n","    Uninstalling Pillow-5.4.1:\n","      Successfully uninstalled Pillow-5.4.1\n","Successfully installed pillow-4.1.1\n","Collecting PIL\n","\u001b[31m  Could not find a version that satisfies the requirement PIL (from versions: )\u001b[0m\n","\u001b[31mNo matching distribution found for PIL\u001b[0m\n","Requirement already satisfied: image in /usr/local/lib/python3.6/dist-packages (1.5.27)\n","Requirement already satisfied: django in /usr/local/lib/python3.6/dist-packages (from image) (2.1.4)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from image) (4.1.1)\n","Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from django->image) (2018.7)\n","Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow->image) (0.46)\n"],"name":"stdout"}]},{"metadata":{"id":"3BnS_2kYkQ43","colab_type":"code","colab":{}},"cell_type":"code","source":["# Imports here\n","import torch\n","import torch.nn as nn\n","from torch import optim\n","import torch.nn.functional as F\n","from torchvision import datasets, transforms\n","import numpy as np\n","%matplotlib inline\n","%config InlineBackend.figure_format = 'retina'\n","\n","import matplotlib.pyplot as plt\n","import helper\n","import PIL"],"execution_count":0,"outputs":[]},{"metadata":{"id":"cr2g0pEUbpdS","colab_type":"code","outputId":"8c2ccd66-e8d8-4737-caad-2326d06b6ced","executionInfo":{"status":"ok","timestamp":1547042167233,"user_tz":-60,"elapsed":1012,"user":{"displayName":"AFOLARIN LAWAL","photoUrl":"https://lh4.googleusercontent.com/-P4xQqKQpsvw/AAAAAAAAAAI/AAAAAAAAANA/k3L-3t5Tctg/s64/photo.jpg","userId":"02010015626091756673"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"cell_type":"code","source":["import os, glob\n","os.getcwd()\n","glob.glob('*')"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['adc.json', 'drive', 'sample_data']"]},"metadata":{"tags":[]},"execution_count":9}]},{"metadata":{"id":"phSjTQk8nx0u","colab_type":"code","colab":{}},"cell_type":"code","source":["data_dir = 'drive/flower_data/'\n","train_dir = data_dir + 'train'\n","valid_dir = data_dir + 'valid'"],"execution_count":0,"outputs":[]},{"metadata":{"id":"MA4_yILD5kiK","colab_type":"code","outputId":"baf91599-0889-48b5-92d4-4714cdb14cc5","executionInfo":{"status":"ok","timestamp":1547042174529,"user_tz":-60,"elapsed":1001,"user":{"displayName":"AFOLARIN LAWAL","photoUrl":"https://lh4.googleusercontent.com/-P4xQqKQpsvw/AAAAAAAAAAI/AAAAAAAAANA/k3L-3t5Tctg/s64/photo.jpg","userId":"02010015626091756673"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"cell_type":"code","source":["# check if CUDA is available\n","train_on_gpu = torch.cuda.is_available()\n","\n","if not train_on_gpu:\n","    print('CUDA is not available.  Training on CPU ...')\n","else:\n","    print('CUDA is available!  Training on GPU ...')"],"execution_count":11,"outputs":[{"output_type":"stream","text":["CUDA is available!  Training on GPU ...\n"],"name":"stdout"}]},{"metadata":{"id":"5drF8VNC665o","colab_type":"code","colab":{}},"cell_type":"code","source":["# TODO: Define your transforms for the training and validation sets\n","train_transforms = transforms.Compose([transforms.Resize(255),\n","                                       transforms.CenterCrop(224),\n","                                       transforms.RandomHorizontalFlip(p=0.2),\n","                                       transforms.RandomVerticalFlip(p=0.2),\n","                                       transforms.ToTensor(),\n","                                       transforms.Normalize((0.485, 0.456, 0.406),\n","                                                          (0.229, 0.224, 0.225))])\n","\n","valid_transforms = transforms.Compose([transforms.Resize(224),\n","                                            transforms.CenterCrop(224),\n","                                            transforms.ToTensor(),\n","                                            transforms.Normalize((0.485, 0.456, 0.406),\n","                                                               (0.229, 0.224, 0.225))]) \n","\n","# TODO: Load the datasets with ImageFolder\n","train_data = datasets.ImageFolder(train_dir, transform = train_transforms)\n","valid_data = datasets.ImageFolder(valid_dir, transform = valid_transforms)\n","\n","# TODO: Using the image datasets and the trainforms, define the dataloaders\n","trainloader = torch.utils.data.DataLoader(train_data, batch_size = 32, shuffle = True)\n","validloader = torch.utils.data.DataLoader(valid_data, batch_size = 32, shuffle = True)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"IwABQX77-zl_","colab_type":"code","outputId":"ba2a9e34-8d5e-4c65-9cc9-a8e771fab4b4","executionInfo":{"status":"ok","timestamp":1547042328232,"user_tz":-60,"elapsed":7458,"user":{"displayName":"AFOLARIN LAWAL","photoUrl":"https://lh4.googleusercontent.com/-P4xQqKQpsvw/AAAAAAAAAAI/AAAAAAAAANA/k3L-3t5Tctg/s64/photo.jpg","userId":"02010015626091756673"}},"colab":{"base_uri":"https://localhost:8080/","height":1890}},"cell_type":"code","source":["import json\n","\n","with open('drive/cat_to_name.json', 'r') as f:\n","  cat_to_name = json.load(f)\n","\n","cat_to_name = dict(cat_to_name)\n","cat_to_name = {int(key): value for key, value in cat_to_name.items()}\n","cat_to_name"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{1: 'pink primrose',\n"," 2: 'hard-leaved pocket orchid',\n"," 3: 'canterbury bells',\n"," 4: 'sweet pea',\n"," 5: 'english marigold',\n"," 6: 'tiger lily',\n"," 7: 'moon orchid',\n"," 8: 'bird of paradise',\n"," 9: 'monkshood',\n"," 10: 'globe thistle',\n"," 11: 'snapdragon',\n"," 12: \"colt's foot\",\n"," 13: 'king protea',\n"," 14: 'spear thistle',\n"," 15: 'yellow iris',\n"," 16: 'globe-flower',\n"," 17: 'purple coneflower',\n"," 18: 'peruvian lily',\n"," 19: 'balloon flower',\n"," 20: 'giant white arum lily',\n"," 21: 'fire lily',\n"," 22: 'pincushion flower',\n"," 23: 'fritillary',\n"," 24: 'red ginger',\n"," 25: 'grape hyacinth',\n"," 26: 'corn poppy',\n"," 27: 'prince of wales feathers',\n"," 28: 'stemless gentian',\n"," 29: 'artichoke',\n"," 30: 'sweet william',\n"," 31: 'carnation',\n"," 32: 'garden phlox',\n"," 33: 'love in the mist',\n"," 34: 'mexican aster',\n"," 35: 'alpine sea holly',\n"," 36: 'ruby-lipped cattleya',\n"," 37: 'cape flower',\n"," 38: 'great masterwort',\n"," 39: 'siam tulip',\n"," 40: 'lenten rose',\n"," 41: 'barbeton daisy',\n"," 42: 'daffodil',\n"," 43: 'sword lily',\n"," 44: 'poinsettia',\n"," 45: 'bolero deep blue',\n"," 46: 'wallflower',\n"," 47: 'marigold',\n"," 48: 'buttercup',\n"," 49: 'oxeye daisy',\n"," 50: 'common dandelion',\n"," 51: 'petunia',\n"," 52: 'wild pansy',\n"," 53: 'primula',\n"," 54: 'sunflower',\n"," 55: 'pelargonium',\n"," 56: 'bishop of llandaff',\n"," 57: 'gaura',\n"," 58: 'geranium',\n"," 59: 'orange dahlia',\n"," 60: 'pink-yellow dahlia',\n"," 61: 'cautleya spicata',\n"," 62: 'japanese anemone',\n"," 63: 'black-eyed susan',\n"," 64: 'silverbush',\n"," 65: 'californian poppy',\n"," 66: 'osteospermum',\n"," 67: 'spring crocus',\n"," 68: 'bearded iris',\n"," 69: 'windflower',\n"," 70: 'tree poppy',\n"," 71: 'gazania',\n"," 72: 'azalea',\n"," 73: 'water lily',\n"," 74: 'rose',\n"," 75: 'thorn apple',\n"," 76: 'morning glory',\n"," 77: 'passion flower',\n"," 78: 'lotus lotus',\n"," 79: 'toad lily',\n"," 80: 'anthurium',\n"," 81: 'frangipani',\n"," 82: 'clematis',\n"," 83: 'hibiscus',\n"," 84: 'columbine',\n"," 85: 'desert-rose',\n"," 86: 'tree mallow',\n"," 87: 'magnolia',\n"," 88: 'cyclamen',\n"," 89: 'watercress',\n"," 90: 'canna lily',\n"," 91: 'hippeastrum',\n"," 92: 'bee balm',\n"," 93: 'ball moss',\n"," 94: 'foxglove',\n"," 95: 'bougainvillea',\n"," 96: 'camellia',\n"," 97: 'mallow',\n"," 98: 'mexican petunia',\n"," 99: 'bromelia',\n"," 100: 'blanket flower',\n"," 101: 'trumpet creeper',\n"," 102: 'blackberry lily'}"]},"metadata":{"tags":[]},"execution_count":13}]},{"metadata":{"id":"w-D_SM6V78xw","colab_type":"code","colab":{}},"cell_type":"code","source":["# Run this to test your data loader\n","#def imshow(image, ax=None, title=None, normalize=True):\n"," #   \"\"\"Imshow for Tensor.\"\"\"\n","  #  if ax is None:\n","   #     fig, ax = plt.subplots()\n","    #image = image.numpy().transpose((1, 2, 0))\n","\n","   # if normalize:\n","    #    mean = np.array([0.485, 0.456, 0.406])\n","     #   std = np.array([0.229, 0.224, 0.225])\n","      #  image = std * image + mean\n","       # image = np.clip(image, 0, 1)\n","\n","    #ax.imshow(image)\n","    #ax.spines['top'].set_visible(False)\n","    #ax.spines['right'].set_visible(False)\n","    #ax.spines['left'].set_visible(False)\n","    #ax.spines['bottom'].set_visible(False)\n","    #ax.tick_params(axis='both', length=0)\n","    #ax.set_xticklabels('')\n","    #ax.set_yticklabels('')\n","\n","    \n","    #return ax\n","\n","\n","#images, labels = next(iter(trainloader))\n","#imshow(images[0], normalize=False)'''"],"execution_count":0,"outputs":[]},{"metadata":{"id":"zs5AQGnq8Euy","colab_type":"code","colab":{}},"cell_type":"code","source":["\n","#vgg19 = models.vgg19(pretrained = True)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"RA7gKpn7t6Xd","colab_type":"code","outputId":"97cf6ccc-7f5c-4c2e-8abc-952ccea1e972","executionInfo":{"status":"ok","timestamp":1547042347580,"user_tz":-60,"elapsed":8652,"user":{"displayName":"AFOLARIN LAWAL","photoUrl":"https://lh4.googleusercontent.com/-P4xQqKQpsvw/AAAAAAAAAAI/AAAAAAAAANA/k3L-3t5Tctg/s64/photo.jpg","userId":"02010015626091756673"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"cell_type":"code","source":["# TODO: Build and train your network\n","\n","import torchvision.models as models\n","vgg11 = models.vgg11(pretrained=True)"],"execution_count":14,"outputs":[{"output_type":"stream","text":["Downloading: \"https://download.pytorch.org/models/vgg11-bbd30ac9.pth\" to /root/.torch/models/vgg11-bbd30ac9.pth\n","100%|██████████| 531456000/531456000 [00:05<00:00, 93194807.86it/s]\n"],"name":"stderr"}]},{"metadata":{"id":"QF8-4a5bbzFP","colab_type":"code","outputId":"a8d5b945-4707-4770-fe69-58fe4ca30def","executionInfo":{"status":"ok","timestamp":1547042351894,"user_tz":-60,"elapsed":998,"user":{"displayName":"AFOLARIN LAWAL","photoUrl":"https://lh4.googleusercontent.com/-P4xQqKQpsvw/AAAAAAAAAAI/AAAAAAAAANA/k3L-3t5Tctg/s64/photo.jpg","userId":"02010015626091756673"}},"colab":{"base_uri":"https://localhost:8080/","height":641}},"cell_type":"code","source":["vgg11"],"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["VGG(\n","  (features): Sequential(\n","    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): ReLU(inplace)\n","    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (4): ReLU(inplace)\n","    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (7): ReLU(inplace)\n","    (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (9): ReLU(inplace)\n","    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (11): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (12): ReLU(inplace)\n","    (13): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (14): ReLU(inplace)\n","    (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (16): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (17): ReLU(inplace)\n","    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (19): ReLU(inplace)\n","    (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (classifier): Sequential(\n","    (0): Linear(in_features=25088, out_features=4096, bias=True)\n","    (1): ReLU(inplace)\n","    (2): Dropout(p=0.5)\n","    (3): Linear(in_features=4096, out_features=4096, bias=True)\n","    (4): ReLU(inplace)\n","    (5): Dropout(p=0.5)\n","    (6): Linear(in_features=4096, out_features=1000, bias=True)\n","  )\n",")"]},"metadata":{"tags":[]},"execution_count":15}]},{"metadata":{"id":"KyUYdjvUj5RS","colab_type":"code","outputId":"714db239-3e7b-45e5-a521-613e33317f27","executionInfo":{"status":"ok","timestamp":1547042356383,"user_tz":-60,"elapsed":944,"user":{"displayName":"AFOLARIN LAWAL","photoUrl":"https://lh4.googleusercontent.com/-P4xQqKQpsvw/AAAAAAAAAAI/AAAAAAAAANA/k3L-3t5Tctg/s64/photo.jpg","userId":"02010015626091756673"}},"colab":{"base_uri":"https://localhost:8080/","height":586}},"cell_type":"code","source":["# Freeze parameters so we don't backprop through them\n","for param in vgg11.parameters():\n","    param.requires_grad = False\n","\n","classifer = nn.Sequential(nn.Linear(25088, 1024),\n","                          nn.ReLU(),\n","                          nn.Dropout(0.2),\n","                          nn.Linear(1024, 102))\n","                          #nn.LogSoftmax(dim=1))\n","vgg11.classifier = classifer\n","vgg11"],"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["VGG(\n","  (features): Sequential(\n","    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): ReLU(inplace)\n","    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (4): ReLU(inplace)\n","    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (7): ReLU(inplace)\n","    (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (9): ReLU(inplace)\n","    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (11): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (12): ReLU(inplace)\n","    (13): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (14): ReLU(inplace)\n","    (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (16): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (17): ReLU(inplace)\n","    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (19): ReLU(inplace)\n","    (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (classifier): Sequential(\n","    (0): Linear(in_features=25088, out_features=1024, bias=True)\n","    (1): ReLU()\n","    (2): Dropout(p=0.2)\n","    (3): Linear(in_features=1024, out_features=102, bias=True)\n","  )\n",")"]},"metadata":{"tags":[]},"execution_count":16}]},{"metadata":{"id":"qWIxXqwU1-Jv","colab_type":"code","colab":{}},"cell_type":"code","source":["criterion = nn.CrossEntropyLoss()\n","\n","# Only train the classifier parameters, feature parameters are frozen\n","optimizer = optim.SGD(filter(lambda p: p.requires_grad, vgg11.parameters()), lr=0.02)\n","\n","# move tensors to GPU if CUDA is available\n","if train_on_gpu:\n","    vgg11.cuda()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"luGDgE5Wo3V3","colab_type":"code","outputId":"9989cd2f-e670-444f-cf53-5d436eca5cb3","executionInfo":{"status":"ok","timestamp":1546878090185,"user_tz":-60,"elapsed":18193,"user":{"displayName":"AFOLARIN LAWAL","photoUrl":"https://lh4.googleusercontent.com/-P4xQqKQpsvw/AAAAAAAAAAI/AAAAAAAAANA/k3L-3t5Tctg/s64/photo.jpg","userId":"02010015626091756673"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"cell_type":"code","source":["images, labels = next(iter(trainloader))\n","images.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([32, 3, 224, 224])"]},"metadata":{"tags":[]},"execution_count":19}]},{"metadata":{"id":"a9Q7BNy12ItZ","colab_type":"code","outputId":"7090db0b-c7ee-4a1b-90ea-3d126a4907bc","executionInfo":{"status":"ok","timestamp":1546887534679,"user_tz":-60,"elapsed":9418859,"user":{"displayName":"AFOLARIN LAWAL","photoUrl":"https://lh4.googleusercontent.com/-P4xQqKQpsvw/AAAAAAAAAAI/AAAAAAAAANA/k3L-3t5Tctg/s64/photo.jpg","userId":"02010015626091756673"}},"colab":{"base_uri":"https://localhost:8080/","height":862}},"cell_type":"code","source":["# number of times to train the epoch\n","num_epoch = 30\n","\n","valid_loss_min = np.inf  # track changes in validation loss\n","\n","for epoch in range(1, num_epoch+1):\n","  \n","  # keep track of training and validation loss\n","  train_loss = 0\n","  valid_loss = 0\n","  running_correct = 0\n","  \n","  ###################\n","  # train the model #\n","  ###################\n","  \n","  vgg11.train()\n","  for images, labels in trainloader:\n","    # move tensors to GPU if CUDA available\n","    if train_on_gpu:\n","      images, labels = images.cuda(), labels.cuda()\n","      \n","    # clear gradents for all optimized variables to prevent accumulations from previous epochs\n","    optimizer.zero_grad()\n","    # forward pass: compute predicted outputs by passing inputs to the model\n","    output = vgg11(images)\n","    # calculate the batch loss\n","    loss = criterion(output, labels)\n","    # backward pass: compute gradient of the loss with respect to model parameters\n","    loss.backward()\n","    # update the weights/paameters based on gradients (optimisation step)\n","    optimizer.step()\n","    # update training loss\n","    train_loss += loss.item() * images.size(0)\n","    \n","          \n","  ######################    \n","  # validate the model #\n","  ######################\n","  vgg11.eval()\n","  for images, labels in validloader:\n","    # move tensors to GPU if CUDA available\n","    if train_on_gpu:\n","      images, labels = images.cuda(), labels.cuda()\n","    \n","    # forward pass: compute predicted outputs by passing inputs to the model\n","    output = vgg11(images)\n","    # calculate the batch loss\n","    loss = criterion(output, labels)\n","    # update average validation loss\n","    valid_loss += loss.item() * images.size(0)\n","    \n","    # calculate accuracy\n","    _, pred = torch.max(output, 1)\n","    # compare predictions with true label\n","    running_correct += torch.sum(pred == labels.data)\n","    \n","  # calculate average losses\n","  train_loss = train_loss/len(trainloader.dataset)\n","  valid_loss = valid_loss/len(validloader.dataset)\n","  accuracy = running_correct.double()/len(validloader.dataset)\n","  \n","  # print training/validation statistics \n","  print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f} \\t Accuracy: {:.6f}'.format(\n","        epoch, train_loss, valid_loss, accuracy))\n","    \n","  # save model if validation loss has decreased\n","  if valid_loss <= valid_loss_min:\n","    print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n","        valid_loss_min,\n","        valid_loss))\n","    torch.save(vgg11.state_dict(), 'vgg11_finalproject.pt')\n","    valid_loss_min = valid_loss\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch: 1 \tTraining Loss: 1.993919 \tValidation Loss: 1.023868 \t Accuracy: 0.702934\n","Validation loss decreased (inf --> 1.023868).  Saving model ...\n","Epoch: 2 \tTraining Loss: 0.472026 \tValidation Loss: 0.569309 \t Accuracy: 0.858191\n","Validation loss decreased (1.023868 --> 0.569309).  Saving model ...\n","Epoch: 3 \tTraining Loss: 0.241408 \tValidation Loss: 0.420482 \t Accuracy: 0.887531\n","Validation loss decreased (0.569309 --> 0.420482).  Saving model ...\n","Epoch: 4 \tTraining Loss: 0.154026 \tValidation Loss: 0.433503 \t Accuracy: 0.896088\n","Epoch: 5 \tTraining Loss: 0.098796 \tValidation Loss: 0.335298 \t Accuracy: 0.915648\n","Validation loss decreased (0.420482 --> 0.335298).  Saving model ...\n","Epoch: 6 \tTraining Loss: 0.087602 \tValidation Loss: 0.321114 \t Accuracy: 0.915648\n","Validation loss decreased (0.335298 --> 0.321114).  Saving model ...\n","Epoch: 7 \tTraining Loss: 0.071166 \tValidation Loss: 0.304043 \t Accuracy: 0.924205\n","Validation loss decreased (0.321114 --> 0.304043).  Saving model ...\n","Epoch: 8 \tTraining Loss: 0.054926 \tValidation Loss: 0.296095 \t Accuracy: 0.920538\n","Validation loss decreased (0.304043 --> 0.296095).  Saving model ...\n","Epoch: 9 \tTraining Loss: 0.049135 \tValidation Loss: 0.308180 \t Accuracy: 0.916870\n","Epoch: 10 \tTraining Loss: 0.040075 \tValidation Loss: 0.278491 \t Accuracy: 0.929095\n","Validation loss decreased (0.296095 --> 0.278491).  Saving model ...\n","Epoch: 11 \tTraining Loss: 0.037053 \tValidation Loss: 0.263197 \t Accuracy: 0.932763\n","Validation loss decreased (0.278491 --> 0.263197).  Saving model ...\n","Epoch: 12 \tTraining Loss: 0.032417 \tValidation Loss: 0.290527 \t Accuracy: 0.924205\n","Epoch: 13 \tTraining Loss: 0.027647 \tValidation Loss: 0.268123 \t Accuracy: 0.932763\n","Epoch: 14 \tTraining Loss: 0.025082 \tValidation Loss: 0.273266 \t Accuracy: 0.927873\n","Epoch: 15 \tTraining Loss: 0.022144 \tValidation Loss: 0.255827 \t Accuracy: 0.930318\n","Validation loss decreased (0.263197 --> 0.255827).  Saving model ...\n","Epoch: 16 \tTraining Loss: 0.021484 \tValidation Loss: 0.257753 \t Accuracy: 0.936430\n","Epoch: 17 \tTraining Loss: 0.017614 \tValidation Loss: 0.258817 \t Accuracy: 0.927873\n","Epoch: 18 \tTraining Loss: 0.016292 \tValidation Loss: 0.255072 \t Accuracy: 0.929095\n","Validation loss decreased (0.255827 --> 0.255072).  Saving model ...\n","Epoch: 19 \tTraining Loss: 0.017812 \tValidation Loss: 0.258005 \t Accuracy: 0.931540\n","Epoch: 20 \tTraining Loss: 0.013704 \tValidation Loss: 0.253654 \t Accuracy: 0.933985\n","Validation loss decreased (0.255072 --> 0.253654).  Saving model ...\n","Epoch: 21 \tTraining Loss: 0.010970 \tValidation Loss: 0.253473 \t Accuracy: 0.927873\n","Validation loss decreased (0.253654 --> 0.253473).  Saving model ...\n","Epoch: 22 \tTraining Loss: 0.011180 \tValidation Loss: 0.250574 \t Accuracy: 0.931540\n","Validation loss decreased (0.253473 --> 0.250574).  Saving model ...\n","Epoch: 23 \tTraining Loss: 0.012377 \tValidation Loss: 0.246129 \t Accuracy: 0.937653\n","Validation loss decreased (0.250574 --> 0.246129).  Saving model ...\n","Epoch: 24 \tTraining Loss: 0.009527 \tValidation Loss: 0.247204 \t Accuracy: 0.929095\n","Epoch: 25 \tTraining Loss: 0.009423 \tValidation Loss: 0.239220 \t Accuracy: 0.940098\n","Validation loss decreased (0.246129 --> 0.239220).  Saving model ...\n","Epoch: 26 \tTraining Loss: 0.009085 \tValidation Loss: 0.240593 \t Accuracy: 0.936430\n","Epoch: 27 \tTraining Loss: 0.009295 \tValidation Loss: 0.270417 \t Accuracy: 0.922983\n","Epoch: 28 \tTraining Loss: 0.009311 \tValidation Loss: 0.242897 \t Accuracy: 0.941320\n","Epoch: 29 \tTraining Loss: 0.009172 \tValidation Loss: 0.251458 \t Accuracy: 0.933985\n","Epoch: 30 \tTraining Loss: 0.006795 \tValidation Loss: 0.248910 \t Accuracy: 0.938875\n"],"name":"stdout"}]},{"metadata":{"id":"92WYqnACbO6u","colab_type":"code","outputId":"d2c2d5dd-14dc-4336-f3a9-6eb4055a60df","executionInfo":{"status":"ok","timestamp":1547042383442,"user_tz":-60,"elapsed":8692,"user":{"displayName":"AFOLARIN LAWAL","photoUrl":"https://lh4.googleusercontent.com/-P4xQqKQpsvw/AAAAAAAAAAI/AAAAAAAAANA/k3L-3t5Tctg/s64/photo.jpg","userId":"02010015626091756673"}},"colab":{"base_uri":"https://localhost:8080/","height":586}},"cell_type":"code","source":["vgg11.load_state_dict(torch.load('drive/vgg11_updatedfinalproject.pt'))\n","vgg11"],"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["VGG(\n","  (features): Sequential(\n","    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): ReLU(inplace)\n","    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (4): ReLU(inplace)\n","    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (7): ReLU(inplace)\n","    (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (9): ReLU(inplace)\n","    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (11): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (12): ReLU(inplace)\n","    (13): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (14): ReLU(inplace)\n","    (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (16): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (17): ReLU(inplace)\n","    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (19): ReLU(inplace)\n","    (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (classifier): Sequential(\n","    (0): Linear(in_features=25088, out_features=1024, bias=True)\n","    (1): ReLU()\n","    (2): Dropout(p=0.2)\n","    (3): Linear(in_features=1024, out_features=102, bias=True)\n","  )\n",")"]},"metadata":{"tags":[]},"execution_count":18}]},{"metadata":{"id":"8MDx3kpKIjqH","colab_type":"code","outputId":"2b51a71e-759c-4da2-c614-a0a097c16b12","executionInfo":{"status":"ok","timestamp":1547047734939,"user_tz":-60,"elapsed":13559,"user":{"displayName":"AFOLARIN LAWAL","photoUrl":"https://lh4.googleusercontent.com/-P4xQqKQpsvw/AAAAAAAAAAI/AAAAAAAAANA/k3L-3t5Tctg/s64/photo.jpg","userId":"02010015626091756673"}},"colab":{"base_uri":"https://localhost:8080/","height":384}},"cell_type":"code","source":["checkpoint = torch.load('drive/vgg11_updatedfinalproject.pt')\n","list(checkpoint.keys())"],"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['features.0.weight',\n"," 'features.0.bias',\n"," 'features.3.weight',\n"," 'features.3.bias',\n"," 'features.6.weight',\n"," 'features.6.bias',\n"," 'features.8.weight',\n"," 'features.8.bias',\n"," 'features.11.weight',\n"," 'features.11.bias',\n"," 'features.13.weight',\n"," 'features.13.bias',\n"," 'features.16.weight',\n"," 'features.16.bias',\n"," 'features.18.weight',\n"," 'features.18.bias',\n"," 'classifier.0.weight',\n"," 'classifier.0.bias',\n"," 'classifier.3.weight',\n"," 'classifier.3.bias']"]},"metadata":{"tags":[]},"execution_count":22}]},{"metadata":{"id":"BrmiD2P16Z24","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":227},"outputId":"596d0aab-1e11-4629-dd88-d0ebe26f18bf","executionInfo":{"status":"error","timestamp":1547042563198,"user_tz":-60,"elapsed":8652,"user":{"displayName":"AFOLARIN LAWAL","photoUrl":"https://lh4.googleusercontent.com/-P4xQqKQpsvw/AAAAAAAAAAI/AAAAAAAAANA/k3L-3t5Tctg/s64/photo.jpg","userId":"02010015626091756673"}}},"cell_type":"code","source":["!mkdir google_test_data\n","!wget -cq https://www.dropbox.xom/s/3zmf1kq58o909rq/google_test_data.zip?dl=1;\n","!unzip -qq google_test_data.zip?dl=1 -d\n","googe_test_data"],"execution_count":20,"outputs":[{"output_type":"stream","text":["error:  must specify directory to which to extract with -d option\n"],"name":"stdout"},{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-20-9bd73e74c128>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'wget -cq https://www.dropbox.xom/s/3zmf1kq58o909rq/google_test_data.zip?dl=1;'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'unzip -qq google_test_data.zip?dl=1 -d'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mgooge_test_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'googe_test_data' is not defined"]}]},{"metadata":{"id":"XYgAIpR6T0ka","colab_type":"code","outputId":"d4d0594a-9272-43b8-f5e4-25d7db436cf3","executionInfo":{"status":"error","timestamp":1547029211955,"user_tz":-60,"elapsed":1240,"user":{"displayName":"AFOLARIN LAWAL","photoUrl":"https://lh4.googleusercontent.com/-P4xQqKQpsvw/AAAAAAAAAAI/AAAAAAAAANA/k3L-3t5Tctg/s64/photo.jpg","userId":"02010015626091756673"}},"colab":{"base_uri":"https://localhost:8080/","height":613}},"cell_type":"code","source":["# import and load test data\n","\n","test_dir = 'drive/test/'\n","\n","test_data = datasets.ImageFolder(test_dir, transform = valid_transforms)\n","\n","test_loader = torch.utils.data.DataLoader(test_data, batch_size = 32)\n"],"execution_count":18,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-18-429c40b8749a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtest_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'drive/test/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageFolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid_transforms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mtest_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, transform, target_transform, loader)\u001b[0m\n\u001b[1;32m    176\u001b[0m         super(ImageFolder, self).__init__(root, loader, IMG_EXTENSIONS,\n\u001b[1;32m    177\u001b[0m                                           \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m                                           target_transform=target_transform)\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, loader, extensions, transform, target_transform)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextensions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextensions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mfind_classes\u001b[0;34m(dir)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mclass_to_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'drive/test/'"]}]},{"metadata":{"id":"rIYsxils_KqJ","colab_type":"code","outputId":"d54f7619-0635-479d-d6c9-f9915603e9c9","executionInfo":{"status":"ok","timestamp":1545947252336,"user_tz":-60,"elapsed":364969,"user":{"displayName":"AFOLARIN LAWAL","photoUrl":"https://lh4.googleusercontent.com/-P4xQqKQpsvw/AAAAAAAAAAI/AAAAAAAAANA/k3L-3t5Tctg/s64/photo.jpg","userId":"02010015626091756673"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"cell_type":"code","source":["# how many samples per batch to load\n","batch_size = 32\n","\n","# track test loss\n","test_loss = 0.0\n","running_correct = 0\n","#class_correct = list(0. for i in range(103))\n","#class_total = list(0. for i in range(103))\n","\n","vgg11.eval()\n","# iterate over test data\n","for images, labels in test_loader:\n","    # move tensors to GPU if CUDA is available\n","    if train_on_gpu:\n","        images, labels = images.cuda(), labels.cuda()\n","    # forward pass: compute predicted outputs by passing inputs to the model\n","    output = vgg11(images)\n","    # calculate the batch loss\n","    loss = criterion(output, labels)\n","    # update test loss \n","    test_loss += loss.item()*images.size(0)\n","    # convert output probabilities to predicted class\n","    _, pred = torch.max(output, 1)    \n","    # compare predictions to true label\n","    running_correct += torch.sum(pred == labels.data)\n","    \n","# average test loss\n","test_loss = test_loss/len(test_loader.dataset)\n","# accuracy of test data\n","accuracy = running_correct.double()/len(test_loader.dataset)\n","\n","# print training/validation statistics \n","print('Test Loss: {:.6f} \\t Accuracy: {:.6f}'.format(\n","      test_loss, accuracy))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Test Loss: 0.492773 \t Accuracy: 0.904762\n"],"name":"stdout"}]},{"metadata":{"id":"WoQvQfR_OCaY","colab_type":"code","outputId":"f69e2339-acea-446d-f8af-0eb6a212ae39","executionInfo":{"status":"ok","timestamp":1545423299681,"user_tz":-60,"elapsed":684,"user":{"displayName":"AFOLARIN LAWAL","photoUrl":"https://lh4.googleusercontent.com/-P4xQqKQpsvw/AAAAAAAAAAI/AAAAAAAAANA/k3L-3t5Tctg/s64/photo.jpg","userId":"02010015626091756673"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"cell_type":"code","source":["output = vgg11(images)\n","images.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([19, 3, 224, 224])"]},"metadata":{"tags":[]},"execution_count":38}]},{"metadata":{"id":"g8scinS5XDVC","colab_type":"code","outputId":"9559aa79-0b9c-4e5b-c8a4-35ca2434589e","executionInfo":{"status":"ok","timestamp":1545412709471,"user_tz":-60,"elapsed":627,"user":{"displayName":"AFOLARIN LAWAL","photoUrl":"https://lh4.googleusercontent.com/-P4xQqKQpsvw/AAAAAAAAAAI/AAAAAAAAANA/k3L-3t5Tctg/s64/photo.jpg","userId":"02010015626091756673"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"cell_type":"code","source":["  _, pred = torch.max(output, 1) \n","pred"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([ 77,  77,  77,  77,  77,  77,  11,  77,  77,  77,  77,  77,\n","         77,  77,  77,  77,  77,  77], device='cuda:0')"]},"metadata":{"tags":[]},"execution_count":23}]},{"metadata":{"id":"aOrKfHafX1M6","colab_type":"code","outputId":"00dbb552-f222-4de4-9c87-faa5e2ebc3fc","executionInfo":{"status":"error","timestamp":1545429537176,"user_tz":-60,"elapsed":10102,"user":{"displayName":"AFOLARIN LAWAL","photoUrl":"https://lh4.googleusercontent.com/-P4xQqKQpsvw/AAAAAAAAAAI/AAAAAAAAANA/k3L-3t5Tctg/s64/photo.jpg","userId":"02010015626091756673"}},"colab":{"base_uri":"https://localhost:8080/","height":319}},"cell_type":"code","source":[" correct_tensor = pred.eq(labels.data.view_as(pred))\n"," correct_tensor.shape"],"execution_count":0,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-57-d0ae67ad27c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcorrect_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcorrect_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mview_as\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m    228\u001b[0m                 \u001b[0;32mas\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m         \"\"\"\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: invalid argument 2: size '[19]' is invalid for input with 20 elements at /pytorch/aten/src/TH/THStorage.c:41"]}]},{"metadata":{"id":"IpA6W7xAxyjf","colab_type":"code","outputId":"f8216bdf-1d03-4bc2-84b7-72a927447782","executionInfo":{"status":"ok","timestamp":1545429550879,"user_tz":-60,"elapsed":507,"user":{"displayName":"AFOLARIN LAWAL","photoUrl":"https://lh4.googleusercontent.com/-P4xQqKQpsvw/AAAAAAAAAAI/AAAAAAAAANA/k3L-3t5Tctg/s64/photo.jpg","userId":"02010015626091756673"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"cell_type":"code","source":["vgg11.parameters()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<generator object Module.parameters at 0x7f8dcc8bdf68>"]},"metadata":{"tags":[]},"execution_count":58}]},{"metadata":{"id":"msUMPUHYx4Q1","colab_type":"code","colab":{}},"cell_type":"code","source":["print('Test Loss: {:.6f}\\n'.format(test_loss))\n","\n","for i in range(1, 103):\n","    if class_total[i] > 0:\n","        print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n","            cat_to_name[i], 100 * class_correct[i] / class_total[i],\n","            np.sum(class_correct[i]), np.sum(class_total[i])))\n","    else:\n","        print('Test Accuracy of %5s: N/A (no training examples)' % (cat_to_name[i]))\n","\n","print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n","    100. * np.sum(class_correct) / np.sum(class_total),\n","    np.sum(class_correct), np.sum(class_total)))"],"execution_count":0,"outputs":[]}]}